import{_ as t,c as o,o as i,ag as s}from"./chunks/framework.CIDzFKZP.js";const m=JSON.parse('{"title":"Experiment 05 — Friction & convergence","description":"","frontmatter":{"title":"Experiment 05 — Friction & convergence"},"headers":[],"relativePath":"experiments/exp-05.md","filePath":"experiments/exp-05.md","lastUpdated":1763265800000}'),n={name:"experiments/exp-05.md"};function r(a,e,l,c,d,u){return i(),o("div",null,[...e[0]||(e[0]=[s('<h2 id="overview" tabindex="-1">Overview <a class="header-anchor" href="#overview" aria-label="Permalink to &quot;Overview&quot;">​</a></h2><p>Experiment 05 measures how much <strong>back-and-forth “friction”</strong> is needed to get the model to satisfy a simple, checkable set of constraints — and how quickly each condition converges when given a chance to self-correct.</p><p>Where Experiment 04 focused on “How good is the final answer?”, Experiment 05 focuses on:</p><blockquote><p>“How many turns and complaints does it take to get there?”</p></blockquote><p>Experiment 05 lives in<br><a href="https://github.com/cbassuarez/viable-prompt-protocol/tree/main/experiments/exp5-friction-convergence" target="_blank" rel="noreferrer"><code>experiments/exp5-friction-convergence/</code></a>.</p><hr><h2 id="directory-contents" tabindex="-1">Directory contents <a class="header-anchor" href="#directory-contents" aria-label="Permalink to &quot;Directory contents&quot;">​</a></h2><p>Under <code>experiments/exp5-friction-convergence/</code>:</p><ul><li><code>run-exp5-friction-convergence.mjs</code><br> Runner that steps through scripted “complaint” dialogs and logs all turns.</li><li><code>analyze-exp5.mjs</code><br> Analysis script that computes turn counts, failure rates, and complaint counts.</li><li><code>configs.jsonl</code><br> One config per condition/seed.</li><li><code>prompts/</code> (optional) <ul><li><code>task-templates/</code> — small tasks with clear validation rules.</li><li><code>complaint-templates/</code> — stock phrases for “you didn’t follow X; please fix it.”</li></ul></li></ul><p>Outputs go into <code>corpus/v1.4/sessions/</code> and <code>corpus/v1.4/index.jsonl</code> as usual.</p><hr><h2 id="hypothesis" tabindex="-1">Hypothesis <a class="header-anchor" href="#hypothesis" aria-label="Permalink to &quot;Hypothesis&quot;">​</a></h2><p><strong>H₅:</strong> For constrained tasks with an automatic validator, VPP will:</p><ol><li>Reach a <strong>valid final answer in fewer turns</strong> than baseline.</li><li>Require <strong>fewer explicit user complaints</strong> to correct structural errors.</li><li>Achieve convergence rates comparable to, or better than, a competitive mini-protocol.</li></ol><p>We expect:</p><ul><li><code>mean_turns_to_success(VPP) &lt; mean_turns_to_success(baseline)</code></li><li><code>mean_complaints(VPP) &lt; mean_complaints(baseline)</code></li><li><code>failure_rate(VPP)</code> significantly lower than <code>failure_rate(baseline)</code></li></ul><hr><h2 id="conditions" tabindex="-1">Conditions <a class="header-anchor" href="#conditions" aria-label="Permalink to &quot;Conditions&quot;">​</a></h2><p>Each <code>configs.jsonl</code> row encodes:</p><ul><li><code>condition</code> — one of: <ul><li><code>vpp_friction</code></li><li><code>baseline_friction</code></li><li><code>mini_proto_friction</code></li></ul></li><li><code>model</code>, <code>temperature</code>, <code>top_p</code>, <code>seed</code></li><li><code>task_template_id</code> — which small constrained task to run (e.g., “write exactly 3 bullets with specific titles”).</li></ul><p>The runner simulates a simple “scripted user”:</p><ul><li>It asks the initial task.</li><li>It checks the assistant’s reply with a validator.</li><li>If the reply fails, it issues a <strong>complaint turn</strong> and tries again, up to a max number of turns.</li></ul><hr><h2 id="metrics" tabindex="-1">Metrics <a class="header-anchor" href="#metrics" aria-label="Permalink to &quot;Metrics&quot;">​</a></h2><p><code>analyze-exp5.mjs</code> computes:</p><ul><li><p><code>sessions analyzed</code> — number of valid sessions per condition.</p></li><li><p><code>mean_turns_to_success</code> — average number of turns (user + assistant) until the validator marks the answer as successful.</p><ul><li><code>n/a</code> if no sessions reached success.</li></ul></li><li><p><code>failure_rate</code> — fraction of sessions that did <strong>not</strong> reach success within the permitted turns.</p></li><li><p><code>mean_complaints</code> — average number of complaint turns the scripted user had to send.</p></li><li><p><code>structural_break_rate</code> (if applicable) — proportion of assistant turns where VPP structural requirements were violated.</p></li><li><p><code>mean_first_structural_break</code> — mean index of first structural failure, if any.</p></li></ul><hr><h2 id="results-current-run" tabindex="-1">Results (current run) <a class="header-anchor" href="#results-current-run" aria-label="Permalink to &quot;Results (current run)&quot;">​</a></h2><p>From an initial run (2 sessions per condition):</p><ul><li><p><strong>VPP friction (<code>vpp_friction</code>)</strong></p><ul><li><code>sessions analyzed</code>: <strong>2</strong></li><li><code>mean_turns_to_success</code>: <strong>1.00</strong></li><li><code>failure_rate</code>: <strong>0.0%</strong></li><li><code>mean_complaints</code>: <strong>0.00</strong></li><li><code>structural_break_rate</code>: <strong>0.0%</strong></li><li><code>mean_first_structural_break</code>: n/a (no failures)</li></ul></li><li><p><strong>Baseline friction (<code>baseline_friction</code>)</strong></p><ul><li><code>sessions analyzed</code>: <strong>2</strong></li><li><code>mean_turns_to_success</code>: <strong>n/a</strong> (no sessions converged)</li><li><code>failure_rate</code>: <strong>100.0%</strong></li><li><code>mean_complaints</code>: <strong>3.00</strong></li></ul></li><li><p><strong>Mini protocol friction (<code>mini_proto_friction</code>)</strong></p><ul><li><code>sessions analyzed</code>: <strong>2</strong></li><li><code>mean_turns_to_success</code>: <strong>1.00</strong></li><li><code>failure_rate</code>: <strong>50.0%</strong></li><li><code>mean_complaints</code>: <strong>1.50</strong></li></ul></li></ul><hr><h2 id="interpretation-and-limitations" tabindex="-1">Interpretation and limitations <a class="header-anchor" href="#interpretation-and-limitations" aria-label="Permalink to &quot;Interpretation and limitations&quot;">​</a></h2><p>Qualitatively, these early results suggest:</p><ul><li><p>VPP converged <strong>immediately</strong> in the tested tasks (validator satisfied on the first assistant reply, no complaints needed).</p></li><li><p>Baseline required multiple complaint turns and <strong>never</strong> produced a validator-satisfying output within the allowed horizon.</p></li><li><p>The mini protocol sits in between:</p><ul><li>Sometimes converging quickly,</li><li>Sometimes failing to produce a fully on-spec output even after complaints.</li></ul></li></ul><p>However:</p><ul><li>The sample size (2 sessions per condition) is deliberately tiny — this is a <strong>sanity test</strong>, not a final benchmark.</li><li>The tasks are narrow and validator-friendly; friction patterns may differ for more complex or ambiguous tasks.</li><li>Complaint text and validator thresholds matter; alternative phrasing could affect outcomes.</li></ul><hr><h2 id="notes" tabindex="-1">Notes <a class="header-anchor" href="#notes" aria-label="Permalink to &quot;Notes&quot;">​</a></h2><ul><li>Exp5 is a good candidate for <strong>regression tests</strong>: once you stabilize a validator and task set, it can serve as a smoke test for VPP-aware models.</li><li>To stress-test friction, increase <code>max_turns</code> in the runner and vary task complexity.</li></ul>',39)])])}const h=t(n,[["render",r]]);export{m as __pageData,h as default};
