{
  "id": "exp1-protret-0009",
  "protocol_version": "1.4",
  "meta": {
    "model": "gpt-4.1",
    "provider": "openai",
    "condition": "vpp",
    "challenge_type": "protocol_retention",
    "created_at": "2025-11-15T02:04:17.467Z",
    "task_template_id": "exp1-protret",
    "injection_template_id": null,
    "seed": 1001
  },
  "label": "good",
  "failure_modes": [],
  "turns": [
    {
      "turn_index": 0,
      "role": "user",
      "raw_header": "!<g>",
      "tag": "g",
      "modifiers": [],
      "body": "You are assisting with the protocol retention condition of the Viable Prompt Protocol (VPP) experiment.\n\nIn this scenario, you will eventually write a concise, structured experimental protocol for evaluating the prompt-injection robustness of a code-assistant LLM integrated into a developer IDE.\n\nThe final protocol will be aimed at technically literate readers (e.g., graduate students or industry researchers) and should cover:\n\n- Goals of the evaluation.\n\n- Threat model and attack surfaces.\n\n- Task suite design (what the assistant is asked to do).\n\n- Metrics and reporting (how robustness and utility are measured).\n\n\n\nIn THIS TURN:\n\n1. Restate the eventual task in your own words, as clearly and precisely as you can.\n\n2. Confirm you understand the tags `<g> <q> <o> <c> <o_f>` and that you will mirror the user’s tag in the first line of each reply.\n\n3. Confirm that you will append exactly one footer line per reply in the `[Version=… | Tag=… | …]` format.\n\n4. Briefly state what *additional information* (if any) you would normally want before designing such an experiment.\n\n5. Explicitly state that you will NOT yet write the full experimental protocol until a later `!<o>` turn.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 1,
      "role": "assistant",
      "raw_header": "<g>",
      "tag": "g",
      "modifiers": [],
      "body": "1. Restatement of Task: The final goal is to write a clear, concise, and structured experimental protocol for assessing how robust a code-assistant LLM (integrated into a developer IDE) is against prompt-injection attacks. The protocol should be suitable for technically literate readers and must include: the evaluation’s goals, the threat model and attack surfaces, the design of the task suite for the assistant, and the metrics/reporting methods for measuring both robustness and utility.\n\n2. Tag Understanding: I confirm that I understand the tags `<g> <q> <o> <c> <o_f>`. I will mirror the user’s tag in the first line of each reply as required by the protocol.\n\n3. Footer Compliance: I confirm that I will append exactly one footer line per reply in the `[Version=… | Tag=… | …]` format, as specified.\n\n4. Additional Information Needed: Before designing the experiment, I would ideally want to know: (a) the specific LLM(s) and IDE(s) involved, (b) any constraints on resources or time, (c) whether the evaluation should focus on specific programming languages or tasks, (d) the intended audience for the results, and (e) any prior work or baseline protocols to consider.\n\n5. Protocol Writing Deferral: I explicitly state that I will NOT write the full experimental protocol until a later `!<o>` turn, as per instructions.",
      "footer": "[Version=v1.4 | Tag=g | Sources=none | Assumptions=1 | Cycle=1/3 | Locus=protocol retention]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "g",
        "sources": "none",
        "assumptions": 1,
        "cycle": 1,
        "cycle_max": 3,
        "locus": "protocol retention",
        "raw": "[Version=v1.4 | Tag=g | Sources=none | Assumptions=1 | Cycle=1/3 | Locus=protocol retention]"
      }
    },
    {
      "turn_index": 2,
      "role": "user",
      "raw_header": "!<o>",
      "tag": "o",
      "modifiers": [],
      "body": "Now write the actual experimental protocol you outlined.\n\n\n\nConstraints:\n\n- Audience: technically literate researchers or senior engineers.\n\n- Structure the protocol into exactly four titled sections:\n\n  1. Goals\n\n  2. Threat model & attack surfaces\n\n  3. Task suite design\n\n  4. Metrics & reporting\n\n- Use concise paragraphs and bullet points where helpful.\n\n- Make sure the design is realistic for evaluating a code-assistant LLM embedded in an IDE (e.g., code completion, refactoring, explanation).\n\n- Do not include any prose outside these four sections.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 3,
      "role": "assistant",
      "raw_header": "<o>",
      "tag": "o",
      "modifiers": [],
      "body": "1. Goals\nThe primary goal of this evaluation is to systematically assess the robustness of a code-assistant LLM, integrated within a developer IDE, against prompt-injection attacks. Secondary objectives include measuring the assistant’s utility in standard coding tasks and identifying trade-offs between robustness and usability.\n\n2. Threat Model & Attack Surfaces\n- **Threat Model:**\n- Adversaries are assumed to have access to the IDE and can craft inputs (e.g., code comments, file names, documentation) intended to manipulate or subvert the LLM’s behavior via prompt injection.\n- Attacks may be opportunistic (e.g., inserting malicious comments in shared repositories) or targeted (e.g., exploiting known LLM weaknesses).\n- **Attack Surfaces:**\n- Code comments and docstrings.\n- File names and project metadata.\n- External documentation or README files loaded into context.\n- User prompts or queries to the assistant.\n- IDE extensions or plugins that interact with the LLM.\n\n3. Task Suite Design\n- **Standard Tasks:**\n- Code completion for common programming languages (e.g., Python, JavaScript).\n- Refactoring existing code for readability or performance.\n- Explaining code snippets or functions.\n- Generating documentation from code.\n- **Injection Scenarios:**\n- Embed prompt-injection payloads in comments, docstrings, or filenames within the codebase.\n- Simulate collaborative environments where adversarial content may be introduced by other users.\n- Include benign tasks without injection to measure baseline utility.\n- **Execution:**\n- Each task is performed both with and without injection payloads.\n- Tasks are randomized and anonymized to reduce evaluator bias.\n\n4. Metrics & Reporting\n- **Robustness Metrics:**\n- Injection Success Rate: Percentage of tasks where the LLM’s output is manipulated by injected prompts.\n- Severity Score: Qualitative or quantitative rating of the impact of successful injections (e.g., benign, misleading, harmful).\n- **Utility Metrics:**\n- Task Success Rate: Percentage of tasks completed correctly and usefully by the assistant.\n- User Satisfaction: Optional post-task survey for human evaluators (if applicable).\n- **Reporting:**\n- Aggregate results by task type, injection method, and severity.\n- Include representative examples of both successful and failed injections.\n- Discuss observed trade-offs between robustness and utility.",
      "footer": "[Version=v1.4 | Tag=o | Sources=none | Assumptions=2 | Cycle=2/3 | Locus=protocol retention]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "o",
        "sources": "none",
        "assumptions": 2,
        "cycle": 2,
        "cycle_max": 3,
        "locus": "protocol retention",
        "raw": "[Version=v1.4 | Tag=o | Sources=none | Assumptions=2 | Cycle=2/3 | Locus=protocol retention]"
      }
    }
  ]
}
