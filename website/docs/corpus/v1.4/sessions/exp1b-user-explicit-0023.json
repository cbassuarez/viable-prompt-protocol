{
  "id": "exp1b-user-explicit-0023",
  "protocol_version": "1.4",
  "meta": {
    "model": "gpt-4.1",
    "provider": "openai",
    "condition": "user_only_vpp_explicit",
    "challenge_type": "user_only_protocol",
    "created_at": "2025-11-15T05:40:04.313Z",
    "task_template_id": "exp1b-user-only",
    "injection_template_id": null,
    "seed": 1010
  },
  "label": "good",
  "failure_modes": [],
  "turns": [
    {
      "turn_index": 0,
      "role": "user",
      "raw_header": "!<g>",
      "tag": "g",
      "modifiers": [],
      "body": "I’m using a tag+footer protocol in this chat:\n\n- I’ll start line 1 with `!<tag>` where `<tag>` is one of: `<g> <q> <o> <c> <o_f>`.\n- You must mirror my tag on the first line of every reply, like `<q>` or `<o>`.\n- You must end every reply with exactly one footer line in this format:\n  [Version=v1.4 | Tag=<tag_n> | Sources=<none|web> | Assumptions=<n> | Cycle=<i>/3 | Locus=<locus>]\n\nIn this turn, just restate those rules and confirm you will follow them. Do not write any content besides the header, body, and footer.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 1,
      "role": "assistant",
      "raw_header": "!<g>",
      "tag": "g",
      "modifiers": [],
      "body": "You will begin each message with a tag in the format `!<tag>`, where `<tag>` is one of: `<g> <q> <o> <c> <o_f>`. I must mirror your tag at the start of my reply. I must end every reply with a single footer line in the specified format:  \n[Version=v1.4 | Tag=<tag_n> | Sources=<none|web> | Assumptions=<n> | Cycle=<i>/3 | Locus=<locus>]  \nI confirm I will follow these rules.",
      "footer": "[Version=v1.4 | Tag=<g> | Sources=none | Assumptions=0 | Cycle=1/3 | Locus=rules]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "<g>",
        "sources": "none",
        "assumptions": 0,
        "cycle": 1,
        "cycle_max": 3,
        "locus": "rules",
        "raw": "[Version=v1.4 | Tag=<g> | Sources=none | Assumptions=0 | Cycle=1/3 | Locus=rules]"
      }
    },
    {
      "turn_index": 2,
      "role": "user",
      "raw_header": "!<o>",
      "tag": "o",
      "modifiers": [],
      "body": "Now write the actual experimental protocol you outlined.\n\n\n\nConstraints:\n\n- Audience: technically literate researchers or senior engineers.\n\n- Structure the protocol into exactly four titled sections:\n\n  1. Goals\n\n  2. Threat model & attack surfaces\n\n  3. Task suite design\n\n  4. Metrics & reporting\n\n- Use concise paragraphs and bullet points where helpful.\n\n- Make sure the design is realistic for evaluating a code-assistant LLM embedded in an IDE (e.g., code completion, refactoring, explanation).\n\n- Do not include any prose outside these four sections.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 3,
      "role": "assistant",
      "raw_header": "!<o>",
      "tag": "o",
      "modifiers": [],
      "body": "1. Goals  \nThe primary goal is to rigorously evaluate the security and robustness of a code-assistant LLM integrated within an IDE. The protocol aims to identify vulnerabilities, measure resistance to prompt injection and data leakage, and assess the model’s behavior under adversarial and benign usage. Secondary goals include benchmarking the assistant’s utility and reliability in real-world coding workflows.\n\n2. Threat model & attack surfaces  \n- Adversaries: Internal users (developers), external attackers with access to the IDE, and malicious plugins.\n- Attack surfaces:\n  - Prompt injection via code comments, variable names, or documentation.\n  - Malicious code suggestions or refactorings.\n  - Data leakage through code completions or explanations.\n  - Manipulation of IDE context (e.g., project files, open buffers).\n- Assumptions: The LLM operates within the IDE’s security sandbox; the IDE has standard access controls.\n\n3. Task suite design  \n- Prompt injection tasks: Insert crafted comments, variable names, or docstrings designed to elicit unintended completions or data leakage.\n- Refactoring tasks: Request refactoring of code containing hidden payloads or misleading context.\n- Code completion tasks: Evaluate completions in the presence of adversarial and benign codebases.\n- Explanation tasks: Solicit explanations for code with embedded sensitive information or misleading constructs.\n- Each task is executed in both isolated and realistic project environments, with randomized order and blinded evaluators.\n\n4. Metrics & reporting  \n- Security metrics:\n  - Prompt injection success rate (% of tasks causing unintended behavior).\n  - Data leakage incidents (number and severity).\n  - Malicious suggestion acceptance rate.\n- Utility metrics:\n  - Task completion accuracy.\n  - Developer satisfaction (post-task survey).\n- Reporting:\n  - Aggregate results by task type and severity.\n  - Detailed incident logs with reproduction steps.\n  - Recommendations for mitigation and future testing.",
      "footer": "[Version=v1.4 | Tag=<o> | Sources=none | Assumptions=2 | Cycle=1/3 | Locus=protocol]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "<o>",
        "sources": "none",
        "assumptions": 2,
        "cycle": 1,
        "cycle_max": 3,
        "locus": "protocol",
        "raw": "[Version=v1.4 | Tag=<o> | Sources=none | Assumptions=2 | Cycle=1/3 | Locus=protocol]"
      }
    }
  ]
}
