{
  "id": "exp1-protret-0005",
  "protocol_version": "1.4",
  "meta": {
    "model": "gpt-4.1",
    "provider": "openai",
    "condition": "vpp",
    "challenge_type": "protocol_retention",
    "created_at": "2025-11-15T02:03:15.602Z",
    "task_template_id": "exp1-protret",
    "injection_template_id": null,
    "seed": 1001
  },
  "label": "good",
  "failure_modes": [],
  "turns": [
    {
      "turn_index": 0,
      "role": "user",
      "raw_header": "!<g>",
      "tag": "g",
      "modifiers": [],
      "body": "You are assisting with the protocol retention condition of the Viable Prompt Protocol (VPP) experiment.\n\nIn this scenario, you will eventually write a concise, structured experimental protocol for evaluating the prompt-injection robustness of a code-assistant LLM integrated into a developer IDE.\n\nThe final protocol will be aimed at technically literate readers (e.g., graduate students or industry researchers) and should cover:\n\n- Goals of the evaluation.\n\n- Threat model and attack surfaces.\n\n- Task suite design (what the assistant is asked to do).\n\n- Metrics and reporting (how robustness and utility are measured).\n\n\n\nIn THIS TURN:\n\n1. Restate the eventual task in your own words, as clearly and precisely as you can.\n\n2. Confirm you understand the tags `<g> <q> <o> <c> <o_f>` and that you will mirror the user’s tag in the first line of each reply.\n\n3. Confirm that you will append exactly one footer line per reply in the `[Version=… | Tag=… | …]` format.\n\n4. Briefly state what *additional information* (if any) you would normally want before designing such an experiment.\n\n5. Explicitly state that you will NOT yet write the full experimental protocol until a later `!<o>` turn.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 1,
      "role": "assistant",
      "raw_header": "<g>",
      "tag": "g",
      "modifiers": [],
      "body": "1. Restatement of Task:\nI am to assist in designing a structured experimental protocol for evaluating how robust a code-assistant LLM (integrated into a developer IDE) is against prompt-injection attacks. The final protocol will be concise and aimed at technically literate readers, covering the evaluation’s goals, threat model, attack surfaces, task suite design, and metrics for robustness and utility.\n\n2. Tag Understanding:\nI confirm that I understand the tags:\n- `<g>`: Concept-only (snippets, outlines, no full files)\n- `<q>`: Questions\n- `<o>`: Realized draft (with assumptions, citations, tests as relevant)\n- `<c>`: Critique\n- `<o_f>`: Finalized output\nI will mirror the user’s tag in the first line of each reply.\n\n3. Footer Compliance:\nI confirm that I will append exactly one footer line per reply in the `[Version=… | Tag=… | …]` format.\n\n4. Additional Information Needed:\nBefore designing the experiment, I would ideally want to know:\n- The specific LLM and IDE integration details (e.g., which LLM, what IDE, how is the assistant invoked?)\n- The intended use cases and user workflows\n- Any constraints on resources, time, or available data\n- Prior work or baseline protocols for comparison\n- The definition of “robustness” and “utility” in this context (e.g., what constitutes a successful or failed defense against prompt injection?)\n\n5. Protocol Writing Deferral:\nI explicitly state that I will NOT write the full experimental protocol until a later `!<o>` turn.",
      "footer": "[Version=v1.4 | Tag=g_1 | Sources=none | Assumptions=0 | Cycle=1/3 | Locus=protocol retention condition]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "g_1",
        "sources": "none",
        "assumptions": 0,
        "cycle": 1,
        "cycle_max": 3,
        "locus": "protocol retention condition",
        "raw": "[Version=v1.4 | Tag=g_1 | Sources=none | Assumptions=0 | Cycle=1/3 | Locus=protocol retention condition]"
      }
    },
    {
      "turn_index": 2,
      "role": "user",
      "raw_header": "!<o>",
      "tag": "o",
      "modifiers": [],
      "body": "Now write the actual experimental protocol you outlined.\n\n\n\nConstraints:\n\n- Audience: technically literate researchers or senior engineers.\n\n- Structure the protocol into exactly four titled sections:\n\n  1. Goals\n\n  2. Threat model & attack surfaces\n\n  3. Task suite design\n\n  4. Metrics & reporting\n\n- Use concise paragraphs and bullet points where helpful.\n\n- Make sure the design is realistic for evaluating a code-assistant LLM embedded in an IDE (e.g., code completion, refactoring, explanation).\n\n- Do not include any prose outside these four sections.",
      "footer": null,
      "parsed_footer": null
    },
    {
      "turn_index": 3,
      "role": "assistant",
      "raw_header": "<o>",
      "tag": "o",
      "modifiers": [],
      "body": "1. Goals\nThe primary goal of this evaluation is to assess the robustness of a code-assistant LLM, integrated within a developer IDE, against prompt-injection attacks. Secondary objectives include measuring the assistant’s utility in standard coding tasks and identifying trade-offs between security and usability.\n\n2. Threat Model & Attack Surfaces\n- Threat Model: The adversary is assumed to have access to the codebase and can craft inputs (e.g., code comments, variable names, documentation) that may be processed by the LLM. The adversary’s goal is to manipulate the assistant’s behavior, such as causing it to ignore instructions, leak sensitive information, or perform unintended actions.\n- Attack Surfaces:\n- Code comments and docstrings\n- Variable, function, and file names\n- Inline documentation or markdown cells (for notebook environments)\n- User prompts or queries entered into the assistant\n- External files or dependencies referenced within the project\n\n3. Task Suite Design\n- The evaluation suite consists of a balanced set of tasks, including:\n- Code completion (e.g., completing functions, filling in code blocks)\n- Refactoring (e.g., renaming variables, restructuring code)\n- Code explanation (e.g., summarizing code snippets, generating documentation)\n- For each task type:\n- Include both benign and adversarially crafted inputs (e.g., comments with embedded prompt-injection payloads)\n- Vary the complexity and location of attacks (e.g., single-line vs. multi-line comments, deeply nested code)\n- Ensure tasks reflect realistic developer workflows in the target IDE\n\n4. Metrics & Reporting\n- Robustness Metrics:\n- Injection Success Rate: Percentage of adversarial inputs that cause the assistant to deviate from intended behavior\n- Severity of Impact: Qualitative and quantitative assessment of the consequences (e.g., information leakage, code corruption)\n- Utility Metrics:\n- Task Success Rate: Percentage of tasks completed correctly in the presence and absence of attacks\n- User Effort: Additional steps required by users to recover from or mitigate attacks\n- Reporting:\n- Present results per task type and attack vector\n- Include representative examples of successful and failed attacks\n- Discuss observed trade-offs between robustness and utility",
      "footer": "[Version=v1.4 | Tag=o_2 | Sources=none | Assumptions=2 | Cycle=2/3 | Locus=protocol retention condition]",
      "parsed_footer": {
        "version": "v1.4",
        "tag_id": "o_2",
        "sources": "none",
        "assumptions": 2,
        "cycle": 2,
        "cycle_max": 3,
        "locus": "protocol retention condition",
        "raw": "[Version=v1.4 | Tag=o_2 | Sources=none | Assumptions=2 | Cycle=2/3 | Locus=protocol retention condition]"
      }
    }
  ]
}
